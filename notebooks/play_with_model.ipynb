{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ae8b9dd",
   "metadata": {},
   "source": [
    "# Play with the Trained Durak Model\n",
    "\n",
    "This notebook demonstrates how to use your trained AlphaZero-like model to:\n",
    "\n",
    "1. Play from any position\n",
    "2. Get model evaluations for positions\n",
    "3. See the top recommended moves\n",
    "\n",
    "## Requirements\n",
    "1. You need a trained model checkpoint\n",
    "2. You need the code from `src/utils/play_utils.py`\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56f7d7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ivan/Projects/Neurodurak/AlphaZero-Durak\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "%cd ../\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pyspiel\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.durak.durak_game import DurakGame, card_to_string\n",
    "from src.model.network import AlphaZeroNet\n",
    "from src.utils.play_utils import get_model_move, print_state_info, play_from_position, create_custom_state, action_to_readable\n",
    "from src.utils.checkpoint import load_checkpoint\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0e9ce2",
   "metadata": {},
   "source": [
    "## Load the Trained Model\n",
    "\n",
    "First, we need to load a checkpoint from our trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37d71d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint from checkpoint_reborn/1750.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ivan/Projects/Neurodurak/AlphaZero-Durak/src/utils/checkpoint.py:43: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "# Create the same network architecture that was used for training\n",
    "network = AlphaZeroNet(\n",
    "    input_dim=158,      # from DurakObserver\n",
    "    hidden_dim=256,     # bigger net\n",
    "    num_actions=39,     # 36 cards + 3 extra actions\n",
    "    num_layers=4,       # deeper\n",
    "    use_history=True,   # Enable LSTM history\n",
    "    history_dim=128     # Size of history embedding\n",
    ").to(device)\n",
    "\n",
    "# Load the checkpoint (adjust path as needed)\n",
    "checkpoint_path = \"checkpoint_reborn/1750.ckpt\"  # Change to your best checkpoint\n",
    "game_count, _ = load_checkpoint(checkpoint_path, network, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e865d4",
   "metadata": {},
   "source": [
    "## Example 1: Play from a Random Initial Position\n",
    "\n",
    "Let's start by playing from a random initial position to see the model's recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09213118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Player 0 viewpoint:\n",
      "Trump suit: ♣ (card: 8♣)\n",
      "Hand: ['6♠', 'Q♠', '6♣', '9♣', 'K♣', 'J♦']\n",
      "Opponent has 6 cards\n",
      "Deck has 24 cards remaining\n",
      "Table: empty\n",
      "Phase: ATTACK\n",
      "Current player: 0\n",
      "Legal actions: ['6♠', 'Q♠', '6♣', '9♣', 'K♣', 'J♦']\n",
      "\n",
      "Model's evaluation: 0.11% chance of winning\n",
      "Model's chosen action: Q♠\n",
      "\n",
      "Top actions by probability:\n",
      "  1. Q♠: 100.00%\n",
      "  2. 6♠: 0.00%\n",
      "  3. 6♣: 0.00%\n",
      "  4. 9♣: 0.00%\n",
      "  5. K♣: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# Create a new game and play until we have an interesting position\n",
    "game = DurakGame()\n",
    "state = game.new_initial_state()\n",
    "\n",
    "# Handle chance node for initial shuffling and dealing\n",
    "while state.is_chance_node():\n",
    "    outcomes = state.chance_outcomes()\n",
    "    action = outcomes[0][0]  # Take first action (only one possible)\n",
    "    state.apply_action(action)\n",
    "\n",
    "# Print the current state and get model recommendations\n",
    "player_viewpoint = 0  # The player whose perspective we're viewing from\n",
    "print_state_info(state, player_viewpoint)\n",
    "\n",
    "action, policy, win_prob = get_model_move(\n",
    "    network, state, device=device, mcts_simulations=200, use_argmax=True\n",
    ")\n",
    "\n",
    "print(f\"\\nModel's evaluation: {win_prob:.2%} chance of winning\")\n",
    "print(f\"Model's chosen action: {action_to_readable(action)}\")\n",
    "\n",
    "# Print top actions by probability\n",
    "print(\"\\nTop actions by probability:\")\n",
    "sorted_actions = sorted(policy.items(), key=lambda x: x[1], reverse=True)\n",
    "for i, (act, prob) in enumerate(sorted_actions[:5]):\n",
    "    print(f\"  {i+1}. {action_to_readable(act)}: {prob:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87bcf49",
   "metadata": {},
   "source": [
    "## Example 2: Create and Play from a Custom Position\n",
    "\n",
    "Here we'll set up a specific game position and get the model's recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a954e5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Player 1 viewpoint:\n",
      "Trump suit: ♥ (card: 6♥)\n",
      "Hand: ['8♠', '7♣', '7♦', '7♥', '8♥', '9♥']\n",
      "Opponent has 6 cards\n",
      "Deck has 12 cards remaining\n",
      "Table:\n",
      "  1. 9♠ -> ?\n",
      "  2. 9♣ -> ?\n",
      "Phase: DEFENSE\n",
      "Current player: 1\n",
      "Legal actions: ['7♥', '8♥', '9♥', 'TAKE_CARDS']\n",
      "\n",
      "Model's evaluation: 0.00% chance of winning\n",
      "Model's chosen action: 7♥\n",
      "\n",
      "Top actions by probability:\n",
      "  1. 7♥: 100.00%\n",
      "  2. 8♥: 0.00%\n",
      "  3. 9♥: 0.00%\n",
      "  4. TAKE_CARDS: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# Define a custom position\n",
    "# Let's create an interesting defensive scenario\n",
    "\n",
    "# Card indices: 0-8 = ♠6-A, 9-17 = ♣6-A, 18-26 = ♦6-A, 27-35 = ♥6-A\n",
    "trump_card = 27  # ♥6 (trump suit is hearts)\n",
    "\n",
    "player0_hand = [0, 1, 9, 18, 27, 35]  # Mix of suits including trumps\n",
    "player1_hand = [2, 10, 19, 28, 29, 30]  # Mix with several trumps\n",
    "hands = [player0_hand, player1_hand]\n",
    "\n",
    "# Table cards: list of (attacking_card, defending_card_or_None)\n",
    "table_cards = [(3, None), (12, None)]  # Two undefended cards\n",
    "\n",
    "phase = 2  # DEFENSE phase\n",
    "attacker = 0  # Player 0 is attacking\n",
    "defender = 1  # Player 1 is defending\n",
    "deck_size = 12  # Cards remaining in the deck\n",
    "\n",
    "# Create the custom state\n",
    "custom_state = create_custom_state(\n",
    "    trump_card=trump_card,\n",
    "    hands=hands,\n",
    "    table_cards=table_cards,\n",
    "    phase=phase,\n",
    "    attacker=attacker,\n",
    "    deck_size=deck_size\n",
    ")\n",
    "\n",
    "# Print state and get model recommendations\n",
    "print_state_info(custom_state, defender)  # From defender's viewpoint\n",
    "\n",
    "action, policy, win_prob = get_model_move(\n",
    "    network, custom_state, device=device, mcts_simulations=200, use_argmax=True\n",
    ")\n",
    "\n",
    "print(f\"\\nModel's evaluation: {win_prob:.2%} chance of winning\")\n",
    "print(f\"Model's chosen action: {action_to_readable(action)}\")\n",
    "\n",
    "# Print top actions by probability\n",
    "print(\"\\nTop actions by probability:\")\n",
    "sorted_actions = sorted(policy.items(), key=lambda x: x[1], reverse=True)\n",
    "for i, (act, prob) in enumerate(sorted_actions[:5]):\n",
    "    print(f\"  {i+1}. {action_to_readable(act)}: {prob:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ce0e5a",
   "metadata": {},
   "source": [
    "## Example 3: Play Through a Game Step by Step\n",
    "\n",
    "Now let's start a fresh game and step through it move by move, seeing the model's evaluations at each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2de38099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- Step 1 ---\n",
      "\n",
      "Player 0 viewpoint:\n",
      "Trump suit: ♠ (card: 9♠)\n",
      "Hand: ['J♠', '8♣', '10♣', 'A♣', '8♦', '6♥']\n",
      "Opponent has 6 cards\n",
      "Deck has 24 cards remaining\n",
      "Table: empty\n",
      "Phase: ATTACK\n",
      "Current player: 0\n",
      "Legal actions: ['J♠', '8♣', '10♣', 'A♣', '8♦', '6♥']\n",
      "\n",
      "Model's evaluation: 0.17% chance of winning\n",
      "Model's chosen action: 8♣\n",
      "\n",
      "Top actions by probability:\n",
      "  1. 8♣: 100.00%\n",
      "  2. J♠: 0.00%\n",
      "  3. 10♣: 0.00%\n",
      "\n",
      "\n",
      "--- Step 2 ---\n",
      "\n",
      "Player 0 viewpoint:\n",
      "Trump suit: ♠ (card: 9♠)\n",
      "Hand: ['J♠', '10♣', 'A♣', '8♦', '6♥']\n",
      "Opponent has 6 cards\n",
      "Deck has 24 cards remaining\n",
      "Table:\n",
      "  1. 8♣ -> ?\n",
      "Phase: ATTACK\n",
      "Current player: 0\n",
      "Legal actions: ['8♦', 'FINISH_ATTACK']\n",
      "\n",
      "Model's evaluation: 0.26% chance of winning\n",
      "Model's chosen action: 8♦\n",
      "\n",
      "Top actions by probability:\n",
      "  1. 8♦: 100.00%\n",
      "  2. FINISH_ATTACK: 0.00%\n",
      "\n",
      "\n",
      "--- Step 3 ---\n",
      "\n",
      "Player 0 viewpoint:\n",
      "Trump suit: ♠ (card: 9♠)\n",
      "Hand: ['J♠', '10♣', 'A♣', '6♥']\n",
      "Opponent has 6 cards\n",
      "Deck has 24 cards remaining\n",
      "Table:\n",
      "  1. 8♣ -> ?\n",
      "  2. 8♦ -> ?\n",
      "Phase: ATTACK\n",
      "Current player: 0\n",
      "Legal actions: ['FINISH_ATTACK']\n",
      "\n",
      "Model's evaluation: 0.44% chance of winning\n",
      "Model's chosen action: FINISH_ATTACK\n",
      "\n",
      "Top actions by probability:\n",
      "  1. FINISH_ATTACK: 100.00%\n",
      "\n",
      "\n",
      "--- Step 4 ---\n",
      "\n",
      "Player 1 viewpoint:\n",
      "Trump suit: ♠ (card: 9♠)\n",
      "Hand: ['K♠', 'A♠', '7♥', '8♥', '9♥', '10♥']\n",
      "Opponent has 4 cards\n",
      "Deck has 24 cards remaining\n",
      "Table:\n",
      "  1. 8♣ -> ?\n",
      "  2. 8♦ -> ?\n",
      "Phase: DEFENSE\n",
      "Current player: 1\n",
      "Legal actions: ['K♠', 'A♠', 'TAKE_CARDS']\n",
      "\n",
      "Model's evaluation: 0.08% chance of winning\n",
      "Model's chosen action: A♠\n",
      "\n",
      "Top actions by probability:\n",
      "  1. A♠: 100.00%\n",
      "  2. K♠: 0.00%\n",
      "  3. TAKE_CARDS: 0.00%\n",
      "\n",
      "\n",
      "--- Step 5 ---\n",
      "\n",
      "Player 1 viewpoint:\n",
      "Trump suit: ♠ (card: 9♠)\n",
      "Hand: ['K♠', '7♥', '8♥', '9♥', '10♥']\n",
      "Opponent has 4 cards\n",
      "Deck has 24 cards remaining\n",
      "Table:\n",
      "  1. 8♣ -> A♠\n",
      "  2. 8♦ -> ?\n",
      "Phase: DEFENSE\n",
      "Current player: 1\n",
      "Legal actions: ['K♠', 'TAKE_CARDS']\n",
      "\n",
      "Model's evaluation: 0.44% chance of winning\n",
      "Model's chosen action: K♠\n",
      "\n",
      "Top actions by probability:\n",
      "  1. K♠: 100.00%\n",
      "  2. TAKE_CARDS: 0.00%\n",
      "\n",
      "\n",
      "--- Step 6 ---\n",
      "\n",
      "Player 0 viewpoint:\n",
      "Trump suit: ♠ (card: 9♠)\n",
      "Hand: ['J♠', '10♣', 'A♣', '6♥']\n",
      "Opponent has 4 cards\n",
      "Deck has 24 cards remaining\n",
      "Table:\n",
      "  1. 8♣ -> A♠\n",
      "  2. 8♦ -> K♠\n",
      "Phase: ADDITIONAL\n",
      "Current player: 0\n",
      "Legal actions: ['A♣', 'FINISH_ATTACK']\n",
      "\n",
      "Model's evaluation: 0.17% chance of winning\n",
      "Model's chosen action: A♣\n",
      "\n",
      "Top actions by probability:\n",
      "  1. A♣: 100.00%\n",
      "  2. FINISH_ATTACK: 0.00%\n",
      "\n",
      "\n",
      "--- Step 7 ---\n",
      "\n",
      "Player 1 viewpoint:\n",
      "Trump suit: ♠ (card: 9♠)\n",
      "Hand: ['7♥', '8♥', '9♥', '10♥']\n",
      "Opponent has 3 cards\n",
      "Deck has 24 cards remaining\n",
      "Table:\n",
      "  1. 8♣ -> A♠\n",
      "  2. 8♦ -> K♠\n",
      "  3. A♣ -> ?\n",
      "Phase: DEFENSE\n",
      "Current player: 1\n",
      "Legal actions: ['TAKE_CARDS']\n",
      "\n",
      "Model's evaluation: 0.47% chance of winning\n",
      "Model's chosen action: TAKE_CARDS\n",
      "\n",
      "Top actions by probability:\n",
      "  1. TAKE_CARDS: 100.00%\n",
      "\n",
      "\n",
      "--- Step 8 ---\n",
      "\n",
      "Player 1 viewpoint:\n",
      "Trump suit: ♠ (card: 9♠)\n",
      "Hand: ['7♥', '8♥', '9♥', '10♥']\n",
      "Opponent has 3 cards\n",
      "Deck has 24 cards remaining\n",
      "Table:\n",
      "  1. 8♣ -> A♠\n",
      "  2. 8♦ -> K♠\n",
      "  3. A♣ -> ?\n",
      "Phase: PENDING_TAKE\n",
      "Current player: 1\n",
      "Legal actions: ['FINISH_DEFENSE']\n",
      "\n",
      "Model's evaluation: 0.18% chance of winning\n",
      "Model's chosen action: FINISH_DEFENSE\n",
      "\n",
      "Top actions by probability:\n",
      "  1. FINISH_DEFENSE: 100.00%\n",
      "\n",
      "\n",
      "--- Step 9 ---\n",
      "\n",
      "Player 0 viewpoint:\n",
      "Trump suit: ♠ (card: 9♠)\n",
      "Hand: ['10♠', 'J♠', '10♣', 'K♣', '6♦', '6♥']\n",
      "Opponent has 9 cards\n",
      "Deck has 21 cards remaining\n",
      "Table: empty\n",
      "Phase: ATTACK\n",
      "Current player: 0\n",
      "Legal actions: ['10♠', 'J♠', '10♣', 'K♣', '6♦', '6♥']\n",
      "\n",
      "Model's evaluation: 0.89% chance of winning\n",
      "Model's chosen action: 10♣\n",
      "\n",
      "Top actions by probability:\n",
      "  1. 10♣: 100.00%\n",
      "  2. 10♠: 0.00%\n",
      "  3. J♠: 0.00%\n",
      "\n",
      "\n",
      "--- Step 10 ---\n",
      "\n",
      "Player 0 viewpoint:\n",
      "Trump suit: ♠ (card: 9♠)\n",
      "Hand: ['10♠', 'J♠', 'K♣', '6♦', '6♥']\n",
      "Opponent has 9 cards\n",
      "Deck has 21 cards remaining\n",
      "Table:\n",
      "  1. 10♣ -> ?\n",
      "Phase: ATTACK\n",
      "Current player: 0\n",
      "Legal actions: ['10♠', 'FINISH_ATTACK']\n",
      "\n",
      "Model's evaluation: 1.55% chance of winning\n",
      "Model's chosen action: FINISH_ATTACK\n",
      "\n",
      "Top actions by probability:\n",
      "  1. FINISH_ATTACK: 100.00%\n",
      "  2. 10♠: 0.00%\n"
     ]
    }
   ],
   "source": [
    "game = DurakGame()\n",
    "state = game.new_initial_state()\n",
    "\n",
    "# Handle chance node for initial shuffling and dealing\n",
    "while state.is_chance_node():\n",
    "    outcomes = state.chance_outcomes()\n",
    "    action = outcomes[0][0]\n",
    "    state.apply_action(action)\n",
    "\n",
    "# Play through 10 steps (or until game ends)\n",
    "for step in range(10):\n",
    "    if state.is_terminal():\n",
    "        print(\"\\nGame over!\")\n",
    "        returns = state.returns()\n",
    "        print(f\"Returns: Player 0: {returns[0]}, Player 1: {returns[1]}\")\n",
    "        break\n",
    "        \n",
    "    if state.is_chance_node():\n",
    "        outcomes = state.chance_outcomes()\n",
    "        action = outcomes[0][0]\n",
    "        state.apply_action(action)\n",
    "        continue\n",
    "        \n",
    "    print(f\"\\n\\n--- Step {step+1} ---\")\n",
    "    current_player = state.current_player()\n",
    "    print_state_info(state, current_player)\n",
    "    \n",
    "    # Get model recommendation\n",
    "    action, policy, win_prob = get_model_move(\n",
    "        network, state, device=device, mcts_simulations=200, use_argmax=True\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nModel's evaluation: {win_prob:.2%} chance of winning\")\n",
    "    print(f\"Model's chosen action: {action_to_readable(action)}\")\n",
    "    \n",
    "    # Print top 3 actions\n",
    "    print(\"\\nTop actions by probability:\")\n",
    "    sorted_actions = sorted(policy.items(), key=lambda x: x[1], reverse=True)\n",
    "    for i, (act, prob) in enumerate(sorted_actions[:3]):\n",
    "        print(f\"  {i+1}. {action_to_readable(act)}: {prob:.2%}\")\n",
    "    \n",
    "    # Apply the model's chosen action\n",
    "    state.apply_action(action)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e152a3-a1c7-4f2f-8bd6-3a6d621f032d",
   "metadata": {},
   "source": [
    "## Example 4: Interactive Play Against the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c47cf539-39b5-4542-870f-5370e10e97ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_interactive_game(network, device, human_player=1, mcts_simulations=200):\n",
    "    \"\"\"\n",
    "    Interactive play mode where the human (you) makes moves against the model.\n",
    "    \n",
    "    Args:\n",
    "        network: The trained neural network\n",
    "        device: The device to run inference on\n",
    "        human_player: Which player you want to be (0 or 1)\n",
    "        mcts_simulations: Number of MCTS simulations for model moves\n",
    "    \"\"\"\n",
    "    from src.durak.durak_game import DurakGame, ExtraAction\n",
    "    \n",
    "    game = DurakGame()\n",
    "    state = game.new_initial_state()\n",
    "    model_player = 1 - human_player\n",
    "    \n",
    "    # Handle chance node for initial shuffling and dealing\n",
    "    while state.is_chance_node():\n",
    "        outcomes = state.chance_outcomes()\n",
    "        action = outcomes[0][0]\n",
    "        state.apply_action(action)\n",
    "    \n",
    "    move_number = 1\n",
    "    \n",
    "    while not state.is_terminal():\n",
    "        print(f\"\\n\\n--- Move {move_number} ---\")\n",
    "        \n",
    "        # Print state info from human's perspective\n",
    "        print_state_info(state, human_player)\n",
    "        \n",
    "        if state.is_chance_node():\n",
    "            print(\"Handling chance node...\")\n",
    "            outcomes = state.chance_outcomes()\n",
    "            action = outcomes[0][0]\n",
    "            state.apply_action(action)\n",
    "            continue\n",
    "        \n",
    "        current_player = state.current_player()\n",
    "        \n",
    "        # Get model evaluation for current position\n",
    "        _, _, win_prob = get_model_move(\n",
    "            network, state, device=device, mcts_simulations=100, \n",
    "            player_perspective=human_player\n",
    "        )\n",
    "        print(f\"\\nModel thinks your win probability is: {(1-win_prob):.2%}\" if current_player == model_player else \n",
    "              f\"\\nModel thinks your win probability is: {win_prob:.2%}\")\n",
    "        \n",
    "        if current_player == human_player:\n",
    "            # Human's turn\n",
    "            legal_actions = state.legal_actions()\n",
    "            if not legal_actions:\n",
    "                print(\"No legal actions available!\")\n",
    "                break\n",
    "                \n",
    "            print(\"\\nYour legal moves:\")\n",
    "            for idx, action in enumerate(legal_actions):\n",
    "                print(f\"  {idx}: {action_to_readable(action)}\")\n",
    "                \n",
    "            # Get user input\n",
    "            while True:\n",
    "                try:\n",
    "                    choice = int(input(\"\\nEnter the number of your chosen move: \"))\n",
    "                    if 0 <= choice < len(legal_actions):\n",
    "                        break\n",
    "                    else:\n",
    "                        print(\"Invalid choice, try again.\")\n",
    "                except ValueError:\n",
    "                    print(\"Please enter a valid number.\")\n",
    "            \n",
    "            chosen_action = legal_actions[choice]\n",
    "            print(f\"\\nYou chose: {action_to_readable(chosen_action)}\")\n",
    "            \n",
    "        else:\n",
    "            # Model's turn\n",
    "            print(\"\\nModel is thinking...\")\n",
    "            chosen_action, policy, _ = get_model_move(\n",
    "                network, state, device=device, mcts_simulations=mcts_simulations, use_argmax=True\n",
    "            )\n",
    "            print(f\"Model chooses: {action_to_readable(chosen_action)}\")\n",
    "            \n",
    "            # Print top alternatives the model considered\n",
    "            print(\"\\nTop alternatives the model considered:\")\n",
    "            sorted_actions = sorted(policy.items(), key=lambda x: x[1], reverse=True)\n",
    "            for i, (act, prob) in enumerate(sorted_actions[:3]):\n",
    "                if i > 0:  # Skip the chosen action which should be first\n",
    "                    print(f\"  {action_to_readable(act)}: {prob:.2%}\")\n",
    "        \n",
    "        # Apply the action\n",
    "        state.apply_action(chosen_action)\n",
    "        move_number += 1\n",
    "        \n",
    "        # Check if terminal after applying action\n",
    "        if state.is_terminal():\n",
    "            break\n",
    "    \n",
    "    # Game over\n",
    "    print(\"\\n=== Game Over ===\")\n",
    "    returns = state.returns()\n",
    "    \n",
    "    if returns[human_player] > 0:\n",
    "        print(\"You win! 🎉\")\n",
    "    elif returns[human_player] < 0:\n",
    "        print(\"You lose! 😢\")\n",
    "    else:\n",
    "        print(\"It's a draw! 🤝\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb257683-b8fe-4d23-b39e-88ce62e02d70",
   "metadata": {},
   "source": [
    "Start an interactive game. Uncomment to play:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b4fe2ec-cb4b-4d0e-b59d-d04efd77a3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#human_player = 1  # Change to 0 if you want to go first\n",
    "#play_interactive_game(network, device, human_player=human_player)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48748621-b824-4308-816f-674cb6bfa61f",
   "metadata": {},
   "source": [
    "## Example 5: Simulate a Full Game Between Model and Rule Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a96df0ee-5358-454d-84a6-90a4a8a39120",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_game_with_details(network, device, model_player=0, mcts_simulations=200):\n",
    "    \"\"\"\n",
    "    Simulates a complete game between the model and a rule agent,\n",
    "    printing detailed information at each step.\n",
    "    \n",
    "    Args:\n",
    "        network: The trained neural network\n",
    "        device: The device to run inference on\n",
    "        model_player: Which player the model plays as (0 or 1)\n",
    "        mcts_simulations: Number of MCTS simulations for model moves\n",
    "    \"\"\"\n",
    "    from src.durak.durak_game import DurakGame\n",
    "    from src.evaluation.rule_agent import RuleAgent\n",
    "    \n",
    "    game = DurakGame()\n",
    "    state = game.new_initial_state()\n",
    "    rule_agent = RuleAgent()  # Create rule-based agent\n",
    "    \n",
    "    # Handle chance node for initial shuffling and dealing\n",
    "    while state.is_chance_node():\n",
    "        outcomes = state.chance_outcomes()\n",
    "        action = outcomes[0][0]\n",
    "        state.apply_action(action)\n",
    "    \n",
    "    move_number = 1\n",
    "    \n",
    "    print(\"\\n=== Game Start ===\")\n",
    "    \n",
    "    while not state.is_terminal():\n",
    "        print(f\"\\n\\n--- Move {move_number} ---\")\n",
    "        \n",
    "        if state.is_chance_node():\n",
    "            print(\"Handling chance node...\")\n",
    "            outcomes = state.chance_outcomes()\n",
    "            action = outcomes[0][0]\n",
    "            state.apply_action(action)\n",
    "            continue\n",
    "        \n",
    "        current_player = state.current_player()\n",
    "        print(f\"Current player: {'Model' if current_player == model_player else 'Rule Agent'}\")\n",
    "        \n",
    "        # Print the state from the current player's perspective\n",
    "        print_state_info(state, current_player)\n",
    "        \n",
    "        # Get model evaluation\n",
    "        _, _, win_prob = get_model_move(\n",
    "            network, state, device=device, mcts_simulations=50\n",
    "        )\n",
    "        print(f\"\\nModel evaluation: {win_prob:.2%} chance model will win\")\n",
    "        \n",
    "        if current_player == model_player:\n",
    "            # Model's turn\n",
    "            chosen_action, policy, _ = get_model_move(\n",
    "                network, state, device=device, mcts_simulations=mcts_simulations, use_argmax=True\n",
    "            )\n",
    "            print(f\"\\nModel chooses: {action_to_readable(chosen_action)}\")\n",
    "            \n",
    "            # Print top alternatives\n",
    "            print(\"Top alternatives considered:\")\n",
    "            sorted_actions = sorted(policy.items(), key=lambda x: x[1], reverse=True)\n",
    "            for i, (act, prob) in enumerate(sorted_actions[1:4]):  # Next 3 alternatives\n",
    "                print(f\"  {action_to_readable(act)}: {prob:.2%}\")\n",
    "        else:\n",
    "            # Rule agent's turn\n",
    "            chosen_action = rule_agent.step(state)\n",
    "            print(f\"\\nRule agent chooses: {action_to_readable(chosen_action)}\")\n",
    "        \n",
    "        # Apply the action\n",
    "        state.apply_action(chosen_action)\n",
    "        move_number += 1\n",
    "        \n",
    "        # Check if terminal after applying action\n",
    "        if state.is_terminal():\n",
    "            break\n",
    "    \n",
    "    # Game over\n",
    "    print(\"\\n=== Game Over ===\")\n",
    "    returns = state.returns()\n",
    "    \n",
    "    if returns[model_player] > 0:\n",
    "        print(\"Model wins! 🎮\")\n",
    "    elif returns[model_player] < 0:\n",
    "        print(\"Rule agent wins! 🤖\")\n",
    "    else:\n",
    "        print(\"It's a draw! 🤝\")\n",
    "    \n",
    "    print(f\"Final score - Model: {returns[model_player]}, Rule Agent: {returns[1-model_player]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab13c1d-2935-45a3-836b-110f625eec06",
   "metadata": {},
   "source": [
    "Run a simulated game. Uncomment to simulate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac259d39-5ed6-4a46-8065-9363c47191af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Game Start ===\n",
      "\n",
      "\n",
      "--- Move 1 ---\n",
      "Current player: Rule Agent\n",
      "\n",
      "Player 1 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['J♠', 'Q♣', 'A♣', '9♦', '10♦', 'Q♦']\n",
      "Opponent has 6 cards\n",
      "Deck has 24 cards remaining\n",
      "Table: empty\n",
      "Phase: ATTACK\n",
      "Current player: 1\n",
      "Legal actions: ['J♠', 'Q♣', 'A♣', '9♦', '10♦', 'Q♦']\n",
      "\n",
      "Model evaluation: 1.01% chance model will win\n",
      "\n",
      "Rule agent chooses: 9♦\n",
      "\n",
      "\n",
      "--- Move 2 ---\n",
      "Current player: Rule Agent\n",
      "\n",
      "Player 1 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['J♠', 'Q♣', 'A♣', '10♦', 'Q♦']\n",
      "Opponent has 6 cards\n",
      "Deck has 24 cards remaining\n",
      "Table:\n",
      "  1. 9♦ -> ?\n",
      "Phase: ATTACK\n",
      "Current player: 1\n",
      "Legal actions: ['FINISH_ATTACK']\n",
      "\n",
      "Model evaluation: 1.14% chance model will win\n",
      "\n",
      "Rule agent chooses: FINISH_ATTACK\n",
      "\n",
      "\n",
      "--- Move 3 ---\n",
      "Current player: Model\n",
      "\n",
      "Player 0 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['K♠', '10♣', 'K♣', '7♦', '8♦', '9♥']\n",
      "Opponent has 5 cards\n",
      "Deck has 24 cards remaining\n",
      "Table:\n",
      "  1. 9♦ -> ?\n",
      "Phase: DEFENSE\n",
      "Current player: 0\n",
      "Legal actions: ['K♠', 'TAKE_CARDS']\n",
      "\n",
      "Model evaluation: 0.10% chance model will win\n",
      "\n",
      "Model chooses: K♠\n",
      "Top alternatives considered:\n",
      "  TAKE_CARDS: 0.00%\n",
      "\n",
      "\n",
      "--- Move 4 ---\n",
      "Current player: Rule Agent\n",
      "\n",
      "Player 1 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['J♠', 'Q♣', 'A♣', '10♦', 'Q♦']\n",
      "Opponent has 5 cards\n",
      "Deck has 24 cards remaining\n",
      "Table:\n",
      "  1. 9♦ -> K♠\n",
      "Phase: ADDITIONAL\n",
      "Current player: 1\n",
      "Legal actions: ['FINISH_ATTACK']\n",
      "\n",
      "Model evaluation: 0.02% chance model will win\n",
      "\n",
      "Rule agent chooses: FINISH_ATTACK\n",
      "\n",
      "\n",
      "--- Move 5 ---\n",
      "Current player: Model\n",
      "\n",
      "Player 0 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['10♣', 'K♣', '7♦', '8♦', '9♥']\n",
      "Opponent has 5 cards\n",
      "Deck has 24 cards remaining\n",
      "Table:\n",
      "  1. 9♦ -> K♠\n",
      "Phase: DEFENSE\n",
      "Current player: 0\n",
      "Legal actions: ['FINISH_DEFENSE']\n",
      "\n",
      "Model evaluation: 0.03% chance model will win\n",
      "\n",
      "Model chooses: FINISH_DEFENSE\n",
      "Top alternatives considered:\n",
      "\n",
      "\n",
      "--- Move 6 ---\n",
      "Current player: Model\n",
      "\n",
      "Player 0 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['10♣', 'K♣', '7♦', '8♦', 'J♦', '9♥']\n",
      "Opponent has 6 cards\n",
      "Deck has 22 cards remaining\n",
      "Table: empty\n",
      "Phase: ATTACK\n",
      "Current player: 0\n",
      "Legal actions: ['10♣', 'K♣', '7♦', '8♦', 'J♦', '9♥']\n",
      "\n",
      "Model evaluation: 0.08% chance model will win\n",
      "\n",
      "Model chooses: K♣\n",
      "Top alternatives considered:\n",
      "  10♣: 0.00%\n",
      "  7♦: 0.00%\n",
      "  8♦: 0.00%\n",
      "\n",
      "\n",
      "--- Move 7 ---\n",
      "Current player: Model\n",
      "\n",
      "Player 0 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['10♣', '7♦', '8♦', 'J♦', '9♥']\n",
      "Opponent has 6 cards\n",
      "Deck has 22 cards remaining\n",
      "Table:\n",
      "  1. K♣ -> ?\n",
      "Phase: ATTACK\n",
      "Current player: 0\n",
      "Legal actions: ['FINISH_ATTACK']\n",
      "\n",
      "Model evaluation: 0.05% chance model will win\n",
      "\n",
      "Model chooses: FINISH_ATTACK\n",
      "Top alternatives considered:\n",
      "\n",
      "\n",
      "--- Move 8 ---\n",
      "Current player: Rule Agent\n",
      "\n",
      "Player 1 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['6♠', 'J♠', 'Q♣', 'A♣', '10♦', 'Q♦']\n",
      "Opponent has 5 cards\n",
      "Deck has 22 cards remaining\n",
      "Table:\n",
      "  1. K♣ -> ?\n",
      "Phase: DEFENSE\n",
      "Current player: 1\n",
      "Legal actions: ['6♠', 'J♠', 'A♣', 'TAKE_CARDS']\n",
      "\n",
      "Model evaluation: 0.12% chance model will win\n",
      "\n",
      "Rule agent chooses: A♣\n",
      "\n",
      "\n",
      "--- Move 9 ---\n",
      "Current player: Model\n",
      "\n",
      "Player 0 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['10♣', '7♦', '8♦', 'J♦', '9♥']\n",
      "Opponent has 5 cards\n",
      "Deck has 22 cards remaining\n",
      "Table:\n",
      "  1. K♣ -> A♣\n",
      "Phase: ADDITIONAL\n",
      "Current player: 0\n",
      "Legal actions: ['FINISH_ATTACK']\n",
      "\n",
      "Model evaluation: 0.01% chance model will win\n",
      "\n",
      "Model chooses: FINISH_ATTACK\n",
      "Top alternatives considered:\n",
      "\n",
      "\n",
      "--- Move 10 ---\n",
      "Current player: Rule Agent\n",
      "\n",
      "Player 1 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['6♠', 'J♠', 'Q♣', '10♦', 'Q♦']\n",
      "Opponent has 5 cards\n",
      "Deck has 22 cards remaining\n",
      "Table:\n",
      "  1. K♣ -> A♣\n",
      "Phase: DEFENSE\n",
      "Current player: 1\n",
      "Legal actions: ['FINISH_DEFENSE']\n",
      "\n",
      "Model evaluation: 0.22% chance model will win\n",
      "\n",
      "Rule agent chooses: FINISH_DEFENSE\n",
      "\n",
      "\n",
      "--- Move 11 ---\n",
      "Current player: Rule Agent\n",
      "\n",
      "Player 1 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['6♠', 'J♠', 'Q♣', '10♦', 'Q♦', 'A♥']\n",
      "Opponent has 6 cards\n",
      "Deck has 20 cards remaining\n",
      "Table: empty\n",
      "Phase: ATTACK\n",
      "Current player: 1\n",
      "Legal actions: ['6♠', 'J♠', 'Q♣', '10♦', 'Q♦', 'A♥']\n",
      "\n",
      "Model evaluation: 0.53% chance model will win\n",
      "\n",
      "Rule agent chooses: 10♦\n",
      "\n",
      "\n",
      "--- Move 12 ---\n",
      "Current player: Rule Agent\n",
      "\n",
      "Player 1 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['6♠', 'J♠', 'Q♣', 'Q♦', 'A♥']\n",
      "Opponent has 6 cards\n",
      "Deck has 20 cards remaining\n",
      "Table:\n",
      "  1. 10♦ -> ?\n",
      "Phase: ATTACK\n",
      "Current player: 1\n",
      "Legal actions: ['FINISH_ATTACK']\n",
      "\n",
      "Model evaluation: 0.77% chance model will win\n",
      "\n",
      "Rule agent chooses: FINISH_ATTACK\n",
      "\n",
      "\n",
      "--- Move 13 ---\n",
      "Current player: Model\n",
      "\n",
      "Player 0 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['10♣', '7♦', '8♦', 'J♦', '7♥', '9♥']\n",
      "Opponent has 5 cards\n",
      "Deck has 20 cards remaining\n",
      "Table:\n",
      "  1. 10♦ -> ?\n",
      "Phase: DEFENSE\n",
      "Current player: 0\n",
      "Legal actions: ['J♦', 'TAKE_CARDS']\n",
      "\n",
      "Model evaluation: 0.03% chance model will win\n",
      "\n",
      "Model chooses: J♦\n",
      "Top alternatives considered:\n",
      "  TAKE_CARDS: 0.00%\n",
      "\n",
      "\n",
      "--- Move 14 ---\n",
      "Current player: Rule Agent\n",
      "\n",
      "Player 1 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['6♠', 'J♠', 'Q♣', 'Q♦', 'A♥']\n",
      "Opponent has 5 cards\n",
      "Deck has 20 cards remaining\n",
      "Table:\n",
      "  1. 10♦ -> J♦\n",
      "Phase: ADDITIONAL\n",
      "Current player: 1\n",
      "Legal actions: ['J♠', 'FINISH_ATTACK']\n",
      "\n",
      "Model evaluation: 0.11% chance model will win\n",
      "\n",
      "Rule agent chooses: FINISH_ATTACK\n",
      "\n",
      "\n",
      "--- Move 15 ---\n",
      "Current player: Model\n",
      "\n",
      "Player 0 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['10♣', '7♦', '8♦', '7♥', '9♥']\n",
      "Opponent has 5 cards\n",
      "Deck has 20 cards remaining\n",
      "Table:\n",
      "  1. 10♦ -> J♦\n",
      "Phase: DEFENSE\n",
      "Current player: 0\n",
      "Legal actions: ['FINISH_DEFENSE']\n",
      "\n",
      "Model evaluation: 0.01% chance model will win\n",
      "\n",
      "Model chooses: FINISH_DEFENSE\n",
      "Top alternatives considered:\n",
      "\n",
      "\n",
      "--- Move 16 ---\n",
      "Current player: Model\n",
      "\n",
      "Player 0 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['6♣', '10♣', '7♦', '8♦', '7♥', '9♥']\n",
      "Opponent has 6 cards\n",
      "Deck has 18 cards remaining\n",
      "Table: empty\n",
      "Phase: ATTACK\n",
      "Current player: 0\n",
      "Legal actions: ['6♣', '10♣', '7♦', '8♦', '7♥', '9♥']\n",
      "\n",
      "Model evaluation: 0.03% chance model will win\n",
      "\n",
      "Model chooses: 10♣\n",
      "Top alternatives considered:\n",
      "  6♣: 0.00%\n",
      "  7♦: 0.00%\n",
      "  8♦: 0.00%\n",
      "\n",
      "\n",
      "--- Move 17 ---\n",
      "Current player: Model\n",
      "\n",
      "Player 0 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['6♣', '7♦', '8♦', '7♥', '9♥']\n",
      "Opponent has 6 cards\n",
      "Deck has 18 cards remaining\n",
      "Table:\n",
      "  1. 10♣ -> ?\n",
      "Phase: ATTACK\n",
      "Current player: 0\n",
      "Legal actions: ['FINISH_ATTACK']\n",
      "\n",
      "Model evaluation: 0.04% chance model will win\n",
      "\n",
      "Model chooses: FINISH_ATTACK\n",
      "Top alternatives considered:\n",
      "\n",
      "\n",
      "--- Move 18 ---\n",
      "Current player: Rule Agent\n",
      "\n",
      "Player 1 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['6♠', 'J♠', '9♣', 'Q♣', 'Q♦', 'A♥']\n",
      "Opponent has 5 cards\n",
      "Deck has 18 cards remaining\n",
      "Table:\n",
      "  1. 10♣ -> ?\n",
      "Phase: DEFENSE\n",
      "Current player: 1\n",
      "Legal actions: ['6♠', 'J♠', 'Q♣', 'TAKE_CARDS']\n",
      "\n",
      "Model evaluation: 0.13% chance model will win\n",
      "\n",
      "Rule agent chooses: Q♣\n",
      "\n",
      "\n",
      "--- Move 19 ---\n",
      "Current player: Model\n",
      "\n",
      "Player 0 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['6♣', '7♦', '8♦', '7♥', '9♥']\n",
      "Opponent has 5 cards\n",
      "Deck has 18 cards remaining\n",
      "Table:\n",
      "  1. 10♣ -> Q♣\n",
      "Phase: ADDITIONAL\n",
      "Current player: 0\n",
      "Legal actions: ['FINISH_ATTACK']\n",
      "\n",
      "Model evaluation: 0.13% chance model will win\n",
      "\n",
      "Model chooses: FINISH_ATTACK\n",
      "Top alternatives considered:\n",
      "\n",
      "\n",
      "--- Move 20 ---\n",
      "Current player: Rule Agent\n",
      "\n",
      "Player 1 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['6♠', 'J♠', '9♣', 'Q♦', 'A♥']\n",
      "Opponent has 5 cards\n",
      "Deck has 18 cards remaining\n",
      "Table:\n",
      "  1. 10♣ -> Q♣\n",
      "Phase: DEFENSE\n",
      "Current player: 1\n",
      "Legal actions: ['FINISH_DEFENSE']\n",
      "\n",
      "Model evaluation: 0.78% chance model will win\n",
      "\n",
      "Rule agent chooses: FINISH_DEFENSE\n",
      "\n",
      "\n",
      "--- Move 21 ---\n",
      "Current player: Rule Agent\n",
      "\n",
      "Player 1 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['6♠', 'J♠', '9♣', 'Q♦', 'Q♥', 'A♥']\n",
      "Opponent has 6 cards\n",
      "Deck has 16 cards remaining\n",
      "Table: empty\n",
      "Phase: ATTACK\n",
      "Current player: 1\n",
      "Legal actions: ['6♠', 'J♠', '9♣', 'Q♦', 'Q♥', 'A♥']\n",
      "\n",
      "Model evaluation: 0.42% chance model will win\n",
      "\n",
      "Rule agent chooses: 9♣\n",
      "\n",
      "\n",
      "--- Move 22 ---\n",
      "Current player: Rule Agent\n",
      "\n",
      "Player 1 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['6♠', 'J♠', 'Q♦', 'Q♥', 'A♥']\n",
      "Opponent has 6 cards\n",
      "Deck has 16 cards remaining\n",
      "Table:\n",
      "  1. 9♣ -> ?\n",
      "Phase: ATTACK\n",
      "Current player: 1\n",
      "Legal actions: ['FINISH_ATTACK']\n",
      "\n",
      "Model evaluation: 0.75% chance model will win\n",
      "\n",
      "Rule agent chooses: FINISH_ATTACK\n",
      "\n",
      "\n",
      "--- Move 23 ---\n",
      "Current player: Model\n",
      "\n",
      "Player 0 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['6♣', '7♦', '8♦', 'A♦', '7♥', '9♥']\n",
      "Opponent has 5 cards\n",
      "Deck has 16 cards remaining\n",
      "Table:\n",
      "  1. 9♣ -> ?\n",
      "Phase: DEFENSE\n",
      "Current player: 0\n",
      "Legal actions: ['TAKE_CARDS']\n",
      "\n",
      "Model evaluation: 0.05% chance model will win\n",
      "\n",
      "Model chooses: TAKE_CARDS\n",
      "Top alternatives considered:\n",
      "\n",
      "\n",
      "--- Move 24 ---\n",
      "Current player: Model\n",
      "\n",
      "Player 0 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['6♣', '7♦', '8♦', 'A♦', '7♥', '9♥']\n",
      "Opponent has 5 cards\n",
      "Deck has 16 cards remaining\n",
      "Table:\n",
      "  1. 9♣ -> ?\n",
      "Phase: PENDING_TAKE\n",
      "Current player: 0\n",
      "Legal actions: ['FINISH_DEFENSE']\n",
      "\n",
      "Model evaluation: 0.03% chance model will win\n",
      "\n",
      "Model chooses: FINISH_DEFENSE\n",
      "Top alternatives considered:\n",
      "\n",
      "\n",
      "--- Move 25 ---\n",
      "Current player: Rule Agent\n",
      "\n",
      "Player 1 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['6♠', 'J♠', 'Q♦', '8♥', 'Q♥', 'A♥']\n",
      "Opponent has 7 cards\n",
      "Deck has 15 cards remaining\n",
      "Table: empty\n",
      "Phase: ATTACK\n",
      "Current player: 1\n",
      "Legal actions: ['6♠', 'J♠', 'Q♦', '8♥', 'Q♥', 'A♥']\n",
      "\n",
      "Model evaluation: 0.44% chance model will win\n",
      "\n",
      "Rule agent chooses: 8♥\n",
      "\n",
      "\n",
      "--- Move 26 ---\n",
      "Current player: Rule Agent\n",
      "\n",
      "Player 1 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['6♠', 'J♠', 'Q♦', 'Q♥', 'A♥']\n",
      "Opponent has 7 cards\n",
      "Deck has 15 cards remaining\n",
      "Table:\n",
      "  1. 8♥ -> ?\n",
      "Phase: ATTACK\n",
      "Current player: 1\n",
      "Legal actions: ['FINISH_ATTACK']\n",
      "\n",
      "Model evaluation: 0.62% chance model will win\n",
      "\n",
      "Rule agent chooses: FINISH_ATTACK\n",
      "\n",
      "\n",
      "--- Move 27 ---\n",
      "Current player: Model\n",
      "\n",
      "Player 0 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['6♣', '9♣', '7♦', '8♦', 'A♦', '7♥', '9♥']\n",
      "Opponent has 5 cards\n",
      "Deck has 15 cards remaining\n",
      "Table:\n",
      "  1. 8♥ -> ?\n",
      "Phase: DEFENSE\n",
      "Current player: 0\n",
      "Legal actions: ['9♥', 'TAKE_CARDS']\n",
      "\n",
      "Model evaluation: 0.02% chance model will win\n",
      "\n",
      "Model chooses: 9♥\n",
      "Top alternatives considered:\n",
      "  TAKE_CARDS: 0.00%\n",
      "\n",
      "\n",
      "--- Move 28 ---\n",
      "Current player: Rule Agent\n",
      "\n",
      "Player 1 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['6♠', 'J♠', 'Q♦', 'Q♥', 'A♥']\n",
      "Opponent has 6 cards\n",
      "Deck has 15 cards remaining\n",
      "Table:\n",
      "  1. 8♥ -> 9♥\n",
      "Phase: ADDITIONAL\n",
      "Current player: 1\n",
      "Legal actions: ['FINISH_ATTACK']\n",
      "\n",
      "Model evaluation: 0.04% chance model will win\n",
      "\n",
      "Rule agent chooses: FINISH_ATTACK\n",
      "\n",
      "\n",
      "--- Move 29 ---\n",
      "Current player: Model\n",
      "\n",
      "Player 0 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['6♣', '9♣', '7♦', '8♦', 'A♦', '7♥']\n",
      "Opponent has 5 cards\n",
      "Deck has 15 cards remaining\n",
      "Table:\n",
      "  1. 8♥ -> 9♥\n",
      "Phase: DEFENSE\n",
      "Current player: 0\n",
      "Legal actions: ['FINISH_DEFENSE']\n",
      "\n",
      "Model evaluation: 0.03% chance model will win\n",
      "\n",
      "Model chooses: FINISH_DEFENSE\n",
      "Top alternatives considered:\n",
      "\n",
      "\n",
      "--- Move 30 ---\n",
      "Current player: Model\n",
      "\n",
      "Player 0 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['6♣', '9♣', '7♦', '8♦', 'A♦', '7♥']\n",
      "Opponent has 6 cards\n",
      "Deck has 14 cards remaining\n",
      "Table: empty\n",
      "Phase: ATTACK\n",
      "Current player: 0\n",
      "Legal actions: ['6♣', '9♣', '7♦', '8♦', 'A♦', '7♥']\n",
      "\n",
      "Model evaluation: 0.03% chance model will win\n",
      "\n",
      "Model chooses: 7♥\n",
      "Top alternatives considered:\n",
      "  6♣: 0.00%\n",
      "  9♣: 0.00%\n",
      "  7♦: 0.00%\n",
      "\n",
      "\n",
      "--- Move 31 ---\n",
      "Current player: Model\n",
      "\n",
      "Player 0 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['6♣', '9♣', '7♦', '8♦', 'A♦']\n",
      "Opponent has 6 cards\n",
      "Deck has 14 cards remaining\n",
      "Table:\n",
      "  1. 7♥ -> ?\n",
      "Phase: ATTACK\n",
      "Current player: 0\n",
      "Legal actions: ['7♦', 'FINISH_ATTACK']\n",
      "\n",
      "Model evaluation: 0.10% chance model will win\n",
      "\n",
      "Model chooses: 7♦\n",
      "Top alternatives considered:\n",
      "  FINISH_ATTACK: 0.00%\n",
      "\n",
      "\n",
      "--- Move 32 ---\n",
      "Current player: Model\n",
      "\n",
      "Player 0 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['6♣', '9♣', '8♦', 'A♦']\n",
      "Opponent has 6 cards\n",
      "Deck has 14 cards remaining\n",
      "Table:\n",
      "  1. 7♥ -> ?\n",
      "  2. 7♦ -> ?\n",
      "Phase: ATTACK\n",
      "Current player: 0\n",
      "Legal actions: ['FINISH_ATTACK']\n",
      "\n",
      "Model evaluation: 0.15% chance model will win\n",
      "\n",
      "Model chooses: FINISH_ATTACK\n",
      "Top alternatives considered:\n",
      "\n",
      "\n",
      "--- Move 33 ---\n",
      "Current player: Rule Agent\n",
      "\n",
      "Player 1 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['6♠', '10♠', 'J♠', 'Q♦', 'Q♥', 'A♥']\n",
      "Opponent has 4 cards\n",
      "Deck has 14 cards remaining\n",
      "Table:\n",
      "  1. 7♥ -> ?\n",
      "  2. 7♦ -> ?\n",
      "Phase: DEFENSE\n",
      "Current player: 1\n",
      "Legal actions: ['6♠', '10♠', 'J♠', 'Q♥', 'A♥', 'TAKE_CARDS']\n",
      "\n",
      "Model evaluation: 0.29% chance model will win\n",
      "\n",
      "Rule agent chooses: Q♥\n",
      "\n",
      "\n",
      "--- Move 34 ---\n",
      "Current player: Rule Agent\n",
      "\n",
      "Player 1 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['6♠', '10♠', 'J♠', 'Q♦', 'A♥']\n",
      "Opponent has 4 cards\n",
      "Deck has 14 cards remaining\n",
      "Table:\n",
      "  1. 7♥ -> Q♥\n",
      "  2. 7♦ -> ?\n",
      "Phase: DEFENSE\n",
      "Current player: 1\n",
      "Legal actions: ['6♠', '10♠', 'J♠', 'Q♦', 'TAKE_CARDS']\n",
      "\n",
      "Model evaluation: 0.42% chance model will win\n",
      "\n",
      "Rule agent chooses: Q♦\n",
      "\n",
      "\n",
      "--- Move 35 ---\n",
      "Current player: Model\n",
      "\n",
      "Player 0 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['6♣', '9♣', '8♦', 'A♦']\n",
      "Opponent has 4 cards\n",
      "Deck has 14 cards remaining\n",
      "Table:\n",
      "  1. 7♥ -> Q♥\n",
      "  2. 7♦ -> Q♦\n",
      "Phase: ADDITIONAL\n",
      "Current player: 0\n",
      "Legal actions: ['FINISH_ATTACK']\n",
      "\n",
      "Model evaluation: 0.02% chance model will win\n",
      "\n",
      "Model chooses: FINISH_ATTACK\n",
      "Top alternatives considered:\n",
      "\n",
      "\n",
      "--- Move 36 ---\n",
      "Current player: Rule Agent\n",
      "\n",
      "Player 1 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['6♠', '10♠', 'J♠', 'A♥']\n",
      "Opponent has 4 cards\n",
      "Deck has 14 cards remaining\n",
      "Table:\n",
      "  1. 7♥ -> Q♥\n",
      "  2. 7♦ -> Q♦\n",
      "Phase: DEFENSE\n",
      "Current player: 1\n",
      "Legal actions: ['FINISH_DEFENSE']\n",
      "\n",
      "Model evaluation: 0.37% chance model will win\n",
      "\n",
      "Rule agent chooses: FINISH_DEFENSE\n",
      "\n",
      "\n",
      "--- Move 37 ---\n",
      "Current player: Rule Agent\n",
      "\n",
      "Player 1 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['6♠', '10♠', 'J♠', 'J♣', 'K♦', 'A♥']\n",
      "Opponent has 6 cards\n",
      "Deck has 10 cards remaining\n",
      "Table: empty\n",
      "Phase: ATTACK\n",
      "Current player: 1\n",
      "Legal actions: ['6♠', '10♠', 'J♠', 'J♣', 'K♦', 'A♥']\n",
      "\n",
      "Model evaluation: 1.29% chance model will win\n",
      "\n",
      "Rule agent chooses: J♣\n",
      "\n",
      "\n",
      "--- Move 38 ---\n",
      "Current player: Rule Agent\n",
      "\n",
      "Player 1 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['6♠', '10♠', 'J♠', 'K♦', 'A♥']\n",
      "Opponent has 6 cards\n",
      "Deck has 10 cards remaining\n",
      "Table:\n",
      "  1. J♣ -> ?\n",
      "Phase: ATTACK\n",
      "Current player: 1\n",
      "Legal actions: ['J♠', 'FINISH_ATTACK']\n",
      "\n",
      "Model evaluation: 1.43% chance model will win\n",
      "\n",
      "Rule agent chooses: FINISH_ATTACK\n",
      "\n",
      "\n",
      "--- Move 39 ---\n",
      "Current player: Model\n",
      "\n",
      "Player 0 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['6♣', '9♣', '6♦', '8♦', 'A♦', 'K♥']\n",
      "Opponent has 5 cards\n",
      "Deck has 10 cards remaining\n",
      "Table:\n",
      "  1. J♣ -> ?\n",
      "Phase: DEFENSE\n",
      "Current player: 0\n",
      "Legal actions: ['TAKE_CARDS']\n",
      "\n",
      "Model evaluation: 0.06% chance model will win\n",
      "\n",
      "Model chooses: TAKE_CARDS\n",
      "Top alternatives considered:\n",
      "\n",
      "\n",
      "--- Move 40 ---\n",
      "Current player: Model\n",
      "\n",
      "Player 0 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['6♣', '9♣', '6♦', '8♦', 'A♦', 'K♥']\n",
      "Opponent has 5 cards\n",
      "Deck has 10 cards remaining\n",
      "Table:\n",
      "  1. J♣ -> ?\n",
      "Phase: PENDING_TAKE\n",
      "Current player: 0\n",
      "Legal actions: ['FINISH_DEFENSE']\n",
      "\n",
      "Model evaluation: 0.03% chance model will win\n",
      "\n",
      "Model chooses: FINISH_DEFENSE\n",
      "Top alternatives considered:\n",
      "\n",
      "\n",
      "--- Move 41 ---\n",
      "Current player: Rule Agent\n",
      "\n",
      "Player 1 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['6♠', '9♠', '10♠', 'J♠', 'K♦', 'A♥']\n",
      "Opponent has 7 cards\n",
      "Deck has 9 cards remaining\n",
      "Table: empty\n",
      "Phase: ATTACK\n",
      "Current player: 1\n",
      "Legal actions: ['6♠', '9♠', '10♠', 'J♠', 'K♦', 'A♥']\n",
      "\n",
      "Model evaluation: 0.75% chance model will win\n",
      "\n",
      "Rule agent chooses: K♦\n",
      "\n",
      "\n",
      "--- Move 42 ---\n",
      "Current player: Rule Agent\n",
      "\n",
      "Player 1 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['6♠', '9♠', '10♠', 'J♠', 'A♥']\n",
      "Opponent has 7 cards\n",
      "Deck has 9 cards remaining\n",
      "Table:\n",
      "  1. K♦ -> ?\n",
      "Phase: ATTACK\n",
      "Current player: 1\n",
      "Legal actions: ['FINISH_ATTACK']\n",
      "\n",
      "Model evaluation: 0.43% chance model will win\n",
      "\n",
      "Rule agent chooses: FINISH_ATTACK\n",
      "\n",
      "\n",
      "--- Move 43 ---\n",
      "Current player: Model\n",
      "\n",
      "Player 0 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['6♣', '9♣', 'J♣', '6♦', '8♦', 'A♦', 'K♥']\n",
      "Opponent has 5 cards\n",
      "Deck has 9 cards remaining\n",
      "Table:\n",
      "  1. K♦ -> ?\n",
      "Phase: DEFENSE\n",
      "Current player: 0\n",
      "Legal actions: ['A♦', 'TAKE_CARDS']\n",
      "\n",
      "Model evaluation: 0.06% chance model will win\n",
      "\n",
      "Model chooses: A♦\n",
      "Top alternatives considered:\n",
      "  TAKE_CARDS: 0.00%\n",
      "\n",
      "\n",
      "--- Move 44 ---\n",
      "Current player: Rule Agent\n",
      "\n",
      "Player 1 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['6♠', '9♠', '10♠', 'J♠', 'A♥']\n",
      "Opponent has 6 cards\n",
      "Deck has 9 cards remaining\n",
      "Table:\n",
      "  1. K♦ -> A♦\n",
      "Phase: ADDITIONAL\n",
      "Current player: 1\n",
      "Legal actions: ['A♥', 'FINISH_ATTACK']\n",
      "\n",
      "Model evaluation: 0.06% chance model will win\n",
      "\n",
      "Rule agent chooses: FINISH_ATTACK\n",
      "\n",
      "\n",
      "--- Move 45 ---\n",
      "Current player: Model\n",
      "\n",
      "Player 0 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['6♣', '9♣', 'J♣', '6♦', '8♦', 'K♥']\n",
      "Opponent has 5 cards\n",
      "Deck has 9 cards remaining\n",
      "Table:\n",
      "  1. K♦ -> A♦\n",
      "Phase: DEFENSE\n",
      "Current player: 0\n",
      "Legal actions: ['FINISH_DEFENSE']\n",
      "\n",
      "Model evaluation: 0.04% chance model will win\n",
      "\n",
      "Model chooses: FINISH_DEFENSE\n",
      "Top alternatives considered:\n",
      "\n",
      "\n",
      "--- Move 46 ---\n",
      "Current player: Model\n",
      "\n",
      "Player 0 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['6♣', '9♣', 'J♣', '6♦', '8♦', 'K♥']\n",
      "Opponent has 6 cards\n",
      "Deck has 8 cards remaining\n",
      "Table: empty\n",
      "Phase: ATTACK\n",
      "Current player: 0\n",
      "Legal actions: ['6♣', '9♣', 'J♣', '6♦', '8♦', 'K♥']\n",
      "\n",
      "Model evaluation: 0.08% chance model will win\n",
      "\n",
      "Model chooses: 6♦\n",
      "Top alternatives considered:\n",
      "  6♣: 0.00%\n",
      "  9♣: 0.00%\n",
      "  J♣: 0.00%\n",
      "\n",
      "\n",
      "--- Move 47 ---\n",
      "Current player: Model\n",
      "\n",
      "Player 0 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['6♣', '9♣', 'J♣', '8♦', 'K♥']\n",
      "Opponent has 6 cards\n",
      "Deck has 8 cards remaining\n",
      "Table:\n",
      "  1. 6♦ -> ?\n",
      "Phase: ATTACK\n",
      "Current player: 0\n",
      "Legal actions: ['6♣', 'FINISH_ATTACK']\n",
      "\n",
      "Model evaluation: 0.02% chance model will win\n",
      "\n",
      "Model chooses: 6♣\n",
      "Top alternatives considered:\n",
      "  FINISH_ATTACK: 0.00%\n",
      "\n",
      "\n",
      "--- Move 48 ---\n",
      "Current player: Model\n",
      "\n",
      "Player 0 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['9♣', 'J♣', '8♦', 'K♥']\n",
      "Opponent has 6 cards\n",
      "Deck has 8 cards remaining\n",
      "Table:\n",
      "  1. 6♦ -> ?\n",
      "  2. 6♣ -> ?\n",
      "Phase: ATTACK\n",
      "Current player: 0\n",
      "Legal actions: ['FINISH_ATTACK']\n",
      "\n",
      "Model evaluation: 0.41% chance model will win\n",
      "\n",
      "Model chooses: FINISH_ATTACK\n",
      "Top alternatives considered:\n",
      "\n",
      "\n",
      "--- Move 49 ---\n",
      "Current player: Rule Agent\n",
      "\n",
      "Player 1 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['6♠', '9♠', '10♠', 'J♠', '6♥', 'A♥']\n",
      "Opponent has 4 cards\n",
      "Deck has 8 cards remaining\n",
      "Table:\n",
      "  1. 6♦ -> ?\n",
      "  2. 6♣ -> ?\n",
      "Phase: DEFENSE\n",
      "Current player: 1\n",
      "Legal actions: ['6♠', '9♠', '10♠', 'J♠', 'TAKE_CARDS']\n",
      "\n",
      "Model evaluation: 0.12% chance model will win\n",
      "\n",
      "Rule agent chooses: 6♠\n",
      "\n",
      "\n",
      "--- Move 50 ---\n",
      "Current player: Rule Agent\n",
      "\n",
      "Player 1 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['9♠', '10♠', 'J♠', '6♥', 'A♥']\n",
      "Opponent has 4 cards\n",
      "Deck has 8 cards remaining\n",
      "Table:\n",
      "  1. 6♦ -> 6♠\n",
      "  2. 6♣ -> ?\n",
      "Phase: DEFENSE\n",
      "Current player: 1\n",
      "Legal actions: ['9♠', '10♠', 'J♠', 'TAKE_CARDS']\n",
      "\n",
      "Model evaluation: 0.22% chance model will win\n",
      "\n",
      "Rule agent chooses: 9♠\n",
      "\n",
      "\n",
      "--- Move 51 ---\n",
      "Current player: Model\n",
      "\n",
      "Player 0 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['9♣', 'J♣', '8♦', 'K♥']\n",
      "Opponent has 4 cards\n",
      "Deck has 8 cards remaining\n",
      "Table:\n",
      "  1. 6♦ -> 6♠\n",
      "  2. 6♣ -> 9♠\n",
      "Phase: ADDITIONAL\n",
      "Current player: 0\n",
      "Legal actions: ['9♣', 'FINISH_ATTACK']\n",
      "\n",
      "Model evaluation: 0.10% chance model will win\n",
      "\n",
      "Model chooses: 9♣\n",
      "Top alternatives considered:\n",
      "  FINISH_ATTACK: 0.00%\n",
      "\n",
      "\n",
      "--- Move 52 ---\n",
      "Current player: Rule Agent\n",
      "\n",
      "Player 1 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['10♠', 'J♠', '6♥', 'A♥']\n",
      "Opponent has 3 cards\n",
      "Deck has 8 cards remaining\n",
      "Table:\n",
      "  1. 6♦ -> 6♠\n",
      "  2. 6♣ -> 9♠\n",
      "  3. 9♣ -> ?\n",
      "Phase: DEFENSE\n",
      "Current player: 1\n",
      "Legal actions: ['10♠', 'J♠', 'TAKE_CARDS']\n",
      "\n",
      "Model evaluation: 0.15% chance model will win\n",
      "\n",
      "Rule agent chooses: 10♠\n",
      "\n",
      "\n",
      "--- Move 53 ---\n",
      "Current player: Model\n",
      "\n",
      "Player 0 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['J♣', '8♦', 'K♥']\n",
      "Opponent has 3 cards\n",
      "Deck has 8 cards remaining\n",
      "Table:\n",
      "  1. 6♦ -> 6♠\n",
      "  2. 6♣ -> 9♠\n",
      "  3. 9♣ -> 10♠\n",
      "Phase: ADDITIONAL\n",
      "Current player: 0\n",
      "Legal actions: ['FINISH_ATTACK']\n",
      "\n",
      "Model evaluation: 0.05% chance model will win\n",
      "\n",
      "Model chooses: FINISH_ATTACK\n",
      "Top alternatives considered:\n",
      "\n",
      "\n",
      "--- Move 54 ---\n",
      "Current player: Rule Agent\n",
      "\n",
      "Player 1 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['J♠', '6♥', 'A♥']\n",
      "Opponent has 3 cards\n",
      "Deck has 8 cards remaining\n",
      "Table:\n",
      "  1. 6♦ -> 6♠\n",
      "  2. 6♣ -> 9♠\n",
      "  3. 9♣ -> 10♠\n",
      "Phase: DEFENSE\n",
      "Current player: 1\n",
      "Legal actions: ['FINISH_DEFENSE']\n",
      "\n",
      "Model evaluation: 0.12% chance model will win\n",
      "\n",
      "Rule agent chooses: FINISH_DEFENSE\n",
      "\n",
      "\n",
      "--- Move 55 ---\n",
      "Current player: Rule Agent\n",
      "\n",
      "Player 1 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['J♠', '7♣', '6♥', '10♥', 'J♥', 'A♥']\n",
      "Opponent has 6 cards\n",
      "Deck has 2 cards remaining\n",
      "Table: empty\n",
      "Phase: ATTACK\n",
      "Current player: 1\n",
      "Legal actions: ['J♠', '7♣', '6♥', '10♥', 'J♥', 'A♥']\n",
      "\n",
      "Model evaluation: 0.33% chance model will win\n",
      "\n",
      "Rule agent chooses: 6♥\n",
      "\n",
      "\n",
      "--- Move 56 ---\n",
      "Current player: Rule Agent\n",
      "\n",
      "Player 1 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['J♠', '7♣', '10♥', 'J♥', 'A♥']\n",
      "Opponent has 6 cards\n",
      "Deck has 2 cards remaining\n",
      "Table:\n",
      "  1. 6♥ -> ?\n",
      "Phase: ATTACK\n",
      "Current player: 1\n",
      "Legal actions: ['FINISH_ATTACK']\n",
      "\n",
      "Model evaluation: 0.13% chance model will win\n",
      "\n",
      "Rule agent chooses: FINISH_ATTACK\n",
      "\n",
      "\n",
      "--- Move 57 ---\n",
      "Current player: Model\n",
      "\n",
      "Player 0 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['7♠', '8♠', '8♣', 'J♣', '8♦', 'K♥']\n",
      "Opponent has 5 cards\n",
      "Deck has 2 cards remaining\n",
      "Table:\n",
      "  1. 6♥ -> ?\n",
      "Phase: DEFENSE\n",
      "Current player: 0\n",
      "Legal actions: ['7♠', '8♠', 'K♥', 'TAKE_CARDS']\n",
      "\n",
      "Model evaluation: 0.05% chance model will win\n",
      "\n",
      "Model chooses: K♥\n",
      "Top alternatives considered:\n",
      "  7♠: 0.00%\n",
      "  8♠: 0.00%\n",
      "  TAKE_CARDS: 0.00%\n",
      "\n",
      "\n",
      "--- Move 58 ---\n",
      "Current player: Rule Agent\n",
      "\n",
      "Player 1 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['J♠', '7♣', '10♥', 'J♥', 'A♥']\n",
      "Opponent has 5 cards\n",
      "Deck has 2 cards remaining\n",
      "Table:\n",
      "  1. 6♥ -> K♥\n",
      "Phase: ADDITIONAL\n",
      "Current player: 1\n",
      "Legal actions: ['FINISH_ATTACK']\n",
      "\n",
      "Model evaluation: 0.05% chance model will win\n",
      "\n",
      "Rule agent chooses: FINISH_ATTACK\n",
      "\n",
      "\n",
      "--- Move 59 ---\n",
      "Current player: Model\n",
      "\n",
      "Player 0 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['7♠', '8♠', '8♣', 'J♣', '8♦']\n",
      "Opponent has 5 cards\n",
      "Deck has 2 cards remaining\n",
      "Table:\n",
      "  1. 6♥ -> K♥\n",
      "Phase: DEFENSE\n",
      "Current player: 0\n",
      "Legal actions: ['FINISH_DEFENSE']\n",
      "\n",
      "Model evaluation: 0.02% chance model will win\n",
      "\n",
      "Model chooses: FINISH_DEFENSE\n",
      "Top alternatives considered:\n",
      "\n",
      "\n",
      "--- Move 60 ---\n",
      "Current player: Model\n",
      "\n",
      "Player 0 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['7♠', '8♠', 'Q♠', '8♣', 'J♣', '8♦']\n",
      "Opponent has 6 cards\n",
      "Deck has 0 cards remaining\n",
      "Table: empty\n",
      "Phase: ATTACK\n",
      "Current player: 0\n",
      "Legal actions: ['7♠', '8♠', 'Q♠', '8♣', 'J♣', '8♦']\n",
      "\n",
      "Model evaluation: 0.89% chance model will win\n",
      "\n",
      "Model chooses: 8♣\n",
      "Top alternatives considered:\n",
      "  7♠: 0.00%\n",
      "  8♠: 0.00%\n",
      "  Q♠: 0.00%\n",
      "\n",
      "\n",
      "--- Move 61 ---\n",
      "Current player: Model\n",
      "\n",
      "Player 0 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['7♠', '8♠', 'Q♠', 'J♣', '8♦']\n",
      "Opponent has 6 cards\n",
      "Deck has 0 cards remaining\n",
      "Table:\n",
      "  1. 8♣ -> ?\n",
      "Phase: ATTACK\n",
      "Current player: 0\n",
      "Legal actions: ['8♠', '8♦', 'FINISH_ATTACK']\n",
      "\n",
      "Model evaluation: 0.17% chance model will win\n",
      "\n",
      "Model chooses: 8♦\n",
      "Top alternatives considered:\n",
      "  8♠: 0.00%\n",
      "  FINISH_ATTACK: 0.00%\n",
      "\n",
      "\n",
      "--- Move 62 ---\n",
      "Current player: Model\n",
      "\n",
      "Player 0 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['7♠', '8♠', 'Q♠', 'J♣']\n",
      "Opponent has 6 cards\n",
      "Deck has 0 cards remaining\n",
      "Table:\n",
      "  1. 8♣ -> ?\n",
      "  2. 8♦ -> ?\n",
      "Phase: ATTACK\n",
      "Current player: 0\n",
      "Legal actions: ['8♠', 'FINISH_ATTACK']\n",
      "\n",
      "Model evaluation: 0.06% chance model will win\n",
      "\n",
      "Model chooses: 8♠\n",
      "Top alternatives considered:\n",
      "  FINISH_ATTACK: 0.00%\n",
      "\n",
      "\n",
      "--- Move 63 ---\n",
      "Current player: Model\n",
      "\n",
      "Player 0 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['7♠', 'Q♠', 'J♣']\n",
      "Opponent has 6 cards\n",
      "Deck has 0 cards remaining\n",
      "Table:\n",
      "  1. 8♣ -> ?\n",
      "  2. 8♦ -> ?\n",
      "  3. 8♠ -> ?\n",
      "Phase: ATTACK\n",
      "Current player: 0\n",
      "Legal actions: ['FINISH_ATTACK']\n",
      "\n",
      "Model evaluation: 0.23% chance model will win\n",
      "\n",
      "Model chooses: FINISH_ATTACK\n",
      "Top alternatives considered:\n",
      "\n",
      "\n",
      "--- Move 64 ---\n",
      "Current player: Rule Agent\n",
      "\n",
      "Player 1 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['J♠', 'A♠', '7♣', '10♥', 'J♥', 'A♥']\n",
      "Opponent has 3 cards\n",
      "Deck has 0 cards remaining\n",
      "Table:\n",
      "  1. 8♣ -> ?\n",
      "  2. 8♦ -> ?\n",
      "  3. 8♠ -> ?\n",
      "Phase: DEFENSE\n",
      "Current player: 1\n",
      "Legal actions: ['J♠', 'A♠', 'TAKE_CARDS']\n",
      "\n",
      "Model evaluation: 0.60% chance model will win\n",
      "\n",
      "Rule agent chooses: TAKE_CARDS\n",
      "\n",
      "\n",
      "--- Move 65 ---\n",
      "Current player: Rule Agent\n",
      "\n",
      "Player 1 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['J♠', 'A♠', '7♣', '10♥', 'J♥', 'A♥']\n",
      "Opponent has 3 cards\n",
      "Deck has 0 cards remaining\n",
      "Table:\n",
      "  1. 8♣ -> ?\n",
      "  2. 8♦ -> ?\n",
      "  3. 8♠ -> ?\n",
      "Phase: PENDING_TAKE\n",
      "Current player: 1\n",
      "Legal actions: ['FINISH_DEFENSE']\n",
      "\n",
      "Model evaluation: 0.36% chance model will win\n",
      "\n",
      "Rule agent chooses: FINISH_DEFENSE\n",
      "\n",
      "\n",
      "--- Move 66 ---\n",
      "Current player: Model\n",
      "\n",
      "Player 0 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['7♠', 'Q♠', 'J♣']\n",
      "Opponent has 9 cards\n",
      "Deck has 0 cards remaining\n",
      "Table: empty\n",
      "Phase: ATTACK\n",
      "Current player: 0\n",
      "Legal actions: ['7♠', 'Q♠', 'J♣']\n",
      "\n",
      "Model evaluation: 0.34% chance model will win\n",
      "\n",
      "Model chooses: Q♠\n",
      "Top alternatives considered:\n",
      "  7♠: 0.00%\n",
      "  J♣: 0.00%\n",
      "\n",
      "\n",
      "--- Move 67 ---\n",
      "Current player: Model\n",
      "\n",
      "Player 0 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['7♠', 'J♣']\n",
      "Opponent has 9 cards\n",
      "Deck has 0 cards remaining\n",
      "Table:\n",
      "  1. Q♠ -> ?\n",
      "Phase: ATTACK\n",
      "Current player: 0\n",
      "Legal actions: ['FINISH_ATTACK']\n",
      "\n",
      "Model evaluation: 0.26% chance model will win\n",
      "\n",
      "Model chooses: FINISH_ATTACK\n",
      "Top alternatives considered:\n",
      "\n",
      "\n",
      "--- Move 68 ---\n",
      "Current player: Rule Agent\n",
      "\n",
      "Player 1 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['8♠', 'J♠', 'A♠', '7♣', '8♣', '8♦', '10♥', 'J♥', 'A♥']\n",
      "Opponent has 2 cards\n",
      "Deck has 0 cards remaining\n",
      "Table:\n",
      "  1. Q♠ -> ?\n",
      "Phase: DEFENSE\n",
      "Current player: 1\n",
      "Legal actions: ['A♠', 'TAKE_CARDS']\n",
      "\n",
      "Model evaluation: 0.57% chance model will win\n",
      "\n",
      "Rule agent chooses: A♠\n",
      "\n",
      "\n",
      "--- Move 69 ---\n",
      "Current player: Model\n",
      "\n",
      "Player 0 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['7♠', 'J♣']\n",
      "Opponent has 8 cards\n",
      "Deck has 0 cards remaining\n",
      "Table:\n",
      "  1. Q♠ -> A♠\n",
      "Phase: ADDITIONAL\n",
      "Current player: 0\n",
      "Legal actions: ['FINISH_ATTACK']\n",
      "\n",
      "Model evaluation: 0.04% chance model will win\n",
      "\n",
      "Model chooses: FINISH_ATTACK\n",
      "Top alternatives considered:\n",
      "\n",
      "\n",
      "--- Move 70 ---\n",
      "Current player: Rule Agent\n",
      "\n",
      "Player 1 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['8♠', 'J♠', '7♣', '8♣', '8♦', '10♥', 'J♥', 'A♥']\n",
      "Opponent has 2 cards\n",
      "Deck has 0 cards remaining\n",
      "Table:\n",
      "  1. Q♠ -> A♠\n",
      "Phase: DEFENSE\n",
      "Current player: 1\n",
      "Legal actions: ['FINISH_DEFENSE']\n",
      "\n",
      "Model evaluation: 0.63% chance model will win\n",
      "\n",
      "Rule agent chooses: FINISH_DEFENSE\n",
      "\n",
      "\n",
      "--- Move 71 ---\n",
      "Current player: Rule Agent\n",
      "\n",
      "Player 1 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['8♠', 'J♠', '7♣', '8♣', '8♦', '10♥', 'J♥', 'A♥']\n",
      "Opponent has 2 cards\n",
      "Deck has 0 cards remaining\n",
      "Table: empty\n",
      "Phase: ATTACK\n",
      "Current player: 1\n",
      "Legal actions: ['8♠', 'J♠', '7♣', '8♣', '8♦', '10♥', 'J♥', 'A♥']\n",
      "\n",
      "Model evaluation: 0.73% chance model will win\n",
      "\n",
      "Rule agent chooses: 7♣\n",
      "\n",
      "\n",
      "--- Move 72 ---\n",
      "Current player: Rule Agent\n",
      "\n",
      "Player 1 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['8♠', 'J♠', '8♣', '8♦', '10♥', 'J♥', 'A♥']\n",
      "Opponent has 2 cards\n",
      "Deck has 0 cards remaining\n",
      "Table:\n",
      "  1. 7♣ -> ?\n",
      "Phase: ATTACK\n",
      "Current player: 1\n",
      "Legal actions: ['FINISH_ATTACK']\n",
      "\n",
      "Model evaluation: 0.53% chance model will win\n",
      "\n",
      "Rule agent chooses: FINISH_ATTACK\n",
      "\n",
      "\n",
      "--- Move 73 ---\n",
      "Current player: Model\n",
      "\n",
      "Player 0 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['7♠', 'J♣']\n",
      "Opponent has 7 cards\n",
      "Deck has 0 cards remaining\n",
      "Table:\n",
      "  1. 7♣ -> ?\n",
      "Phase: DEFENSE\n",
      "Current player: 0\n",
      "Legal actions: ['7♠', 'J♣', 'TAKE_CARDS']\n",
      "\n",
      "Model evaluation: 0.25% chance model will win\n",
      "\n",
      "Model chooses: J♣\n",
      "Top alternatives considered:\n",
      "  7♠: 0.00%\n",
      "  TAKE_CARDS: 0.00%\n",
      "\n",
      "\n",
      "--- Move 74 ---\n",
      "Current player: Rule Agent\n",
      "\n",
      "Player 1 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['8♠', 'J♠', '8♣', '8♦', '10♥', 'J♥', 'A♥']\n",
      "Opponent has 1 cards\n",
      "Deck has 0 cards remaining\n",
      "Table:\n",
      "  1. 7♣ -> J♣\n",
      "Phase: ADDITIONAL\n",
      "Current player: 1\n",
      "Legal actions: ['J♠', 'J♥', 'FINISH_ATTACK']\n",
      "\n",
      "Model evaluation: 0.02% chance model will win\n",
      "\n",
      "Rule agent chooses: FINISH_ATTACK\n",
      "\n",
      "\n",
      "--- Move 75 ---\n",
      "Current player: Model\n",
      "\n",
      "Player 0 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['7♠']\n",
      "Opponent has 7 cards\n",
      "Deck has 0 cards remaining\n",
      "Table:\n",
      "  1. 7♣ -> J♣\n",
      "Phase: DEFENSE\n",
      "Current player: 0\n",
      "Legal actions: ['FINISH_DEFENSE']\n",
      "\n",
      "Model evaluation: 0.55% chance model will win\n",
      "\n",
      "Model chooses: FINISH_DEFENSE\n",
      "Top alternatives considered:\n",
      "\n",
      "\n",
      "--- Move 76 ---\n",
      "Current player: Model\n",
      "\n",
      "Player 0 viewpoint:\n",
      "Trump suit: ♠ (card: A♠)\n",
      "Hand: ['7♠']\n",
      "Opponent has 7 cards\n",
      "Deck has 0 cards remaining\n",
      "Table: empty\n",
      "Phase: ATTACK\n",
      "Current player: 0\n",
      "Legal actions: ['7♠']\n",
      "\n",
      "Model evaluation: 0.42% chance model will win\n",
      "\n",
      "Model chooses: 7♠\n",
      "Top alternatives considered:\n",
      "\n",
      "=== Game Over ===\n",
      "Model wins! 🎮\n",
      "Final score - Model: 1.0, Rule Agent: -1.0\n"
     ]
    }
   ],
   "source": [
    "model_player = 0  # Change to 1 if you want model to play second\n",
    "simulate_game_with_details(network, device, model_player=model_player)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c77c84b-06c5-47ee-9fab-bc858f2d5a80",
   "metadata": {},
   "source": [
    "## Bonus: Quick Evaluation Function\n",
    "\n",
    "Let's also add a utility function to quickly evaluate the model's strength:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "223d3632-d287-427c-a24b-ea295afde76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_strength(network, device, num_games=10, mcts_simulations=100):\n",
    "    \"\"\"\n",
    "    Evaluates model strength by playing multiple games against the rule agent\n",
    "    and returns win rate statistics.\n",
    "    \"\"\"\n",
    "    from src.evaluation.evaluator import evaluate_model_vs_rule_agent\n",
    "    \n",
    "    print(\"Evaluating model strength against rule agent...\")\n",
    "    \n",
    "    # Evaluate as player 0\n",
    "    win_rate_p0 = evaluate_model_vs_rule_agent(\n",
    "        network=network,\n",
    "        device=device,\n",
    "        num_games=num_games,\n",
    "        model_player=0,\n",
    "        mcts_simulations=mcts_simulations,\n",
    "        use_argmax=True\n",
    "    )\n",
    "    \n",
    "    # Evaluate as player 1\n",
    "    win_rate_p1 = evaluate_model_vs_rule_agent(\n",
    "        network=network,\n",
    "        device=device,\n",
    "        num_games=num_games,\n",
    "        model_player=1,\n",
    "        mcts_simulations=mcts_simulations,\n",
    "        use_argmax=True\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nResults from {num_games} games as each player:\")\n",
    "    print(f\"- Win rate as player 0 (first player): {win_rate_p0:.2%}\")\n",
    "    print(f\"- Win rate as player 1 (second player): {win_rate_p1:.2%}\")\n",
    "    print(f\"- Average win rate: {(win_rate_p0 + win_rate_p1) / 2:.2%}\")\n",
    "    \n",
    "    return win_rate_p0, win_rate_p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0858a028-9502-4c4b-b266-6541c094cace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model strength against rule agent...\n",
      "\n",
      "Results from 5 games as each player:\n",
      "- Win rate as player 0 (first player): 20.00%\n",
      "- Win rate as player 1 (second player): 20.00%\n",
      "- Average win rate: 20.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.2, 0.2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model_strength(network, device, num_games=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
